{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitpokemonvenvvenvfdba690a281840daa1a27eda3a6bb1f9",
   "display_name": "Python 3.8.2 64-bit ('pokemon-venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA On Pokemon Images\n",
    "This dataset contains 124x124 images of each Pokemon from generations one through seven. Also included is a CSV with each pokemon's type and subtype. I noticed that some images are of pngs and others are jpgs. I'd like to find the difference if any in the representation of both of these image types when they are converted to numpy arrays. If there is a difference I will write a script to convert the data into a common format, whichever is better suited to the application of deep learning. I also want to make sure that all of the images are the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image \n",
    "from numpy import asarray\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/gerardo/Desktop/Projects/Datasets/Pokemon/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "809\n"
    }
   ],
   "source": [
    "print(len(os.listdir(dataset_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 809 images. I wonder if this will be enough to train a decent model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(120, 120, 3)"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "test = dataset_path + \"/\" + \"araquanid.jpg\"\n",
    "test_image = image.imread(test)\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(120, 120, 4)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "test2 = dataset_path + \"/\" + \"absol.png\"\n",
    "test2_image = image.imread(test2)\n",
    "test2_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that a jpg image has 3 color dimensions while a png has 4. I want to make sure that all images are at least the same height and width. I check this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Iterate through all images and check their size, print the filename of those that don't match the standard\n",
    "for file in os.listdir(dataset_path):\n",
    "    picture_path = dataset_path + \"/\" + file\n",
    "    picture = image.imread(picture_path)\n",
    "    if (picture.shape) != (120,120,4) and (picture.shape != (120,120,3)):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell returned nothing so all of the images are the same height and width. In an effort to reduce the size of the dimension of the training data and thus the required size of the network I am going to convert all png images into jpeg images for training. This was accomplished with the ```transform.sh``` script. One concern is that the images that were converted to jpeg from png all have a black background while the rest of the images have a white background. It appears that the white background images are a small minority and thus removing them from the dataset might not be too detrimental. For now I will leave them in and see how it affects training."
   ]
  }
 ]
}